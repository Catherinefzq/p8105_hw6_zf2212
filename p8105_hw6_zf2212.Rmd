---
title: "p8105_hw6_zf2212"
author: "Catherine"
date: "11/24/2018"
output: github_document
---
### Context 

This assignment reinforces ideas in Linear Models.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(modelr)
library("leaps")
```

### Problem 1

#### 1.1
Create a city_state variable and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. Modifiy victim_race to have categories white and non-white, with white as the reference category. Be sure that victim_age is numeric.

```{r import data}
homicides_raw = read.csv("./data_homicides/homicide_data.csv") %>% 
  janitor::clean_names()
```

```{r problem 1.1 munipulation}
homicides_data = homicides_raw %>%
  # creat a new variable, binary variable
  mutate(city_state = str_c(city, state, sep = ", "),
         resolved = ifelse(disposition == "Closed by arrest", 1, 0)) %>% 
  # omit some cities
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>% 
  # modify race and age
  mutate(victim_race, victim_race = ifelse(victim_race == "White", "white", "non-white"),
         victim_race = fct_relevel(victim_race, "white"),
         victim_age = as.numeric(victim_age)) 
```

`city_state` includes the city and state information of each cases.

`resolved` indicates whether the homicide is solved, `0` is unsolved and `1` is solved.

`victim_race` is cataogrized by `white` and `non-white`.

`victim_age` is an `r typeof(homicides_data$victim_age)`.

#### 1.2
For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed.

```{r problem 1.2 baltimore}
# filter baltimore data
btm_data = homicides_data %>% 
  filter(city_state == "Baltimore, MD")
# fit the regression model
btm_logistic = 
  btm_data %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 
# apply broom::tidy 
btm_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         conf_low = exp(estimate - std.error*1.96),
         conf_up = exp(estimate + std.error*1.96)) %>% # transform back
  select(term, log_OR = estimate, OR, p.value, conf_low, conf_up) %>% 
  filter(term == "victim_racenon-white") %>% 
  select(-term) %>% 
  knitr::kable(digits = 3)
```

Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

```{r problem 1.3 all cities function}
race_compare = function(glm){
  
  table = glm %>% 
    broom::tidy() %>% 
    mutate(OR = exp(estimate),
         conf_low = exp(estimate - std.error*1.96),
         conf_up = exp(estimate + std.error*1.96)) %>% 
    select(term, log_OR = estimate, OR, p.value, conf_low, conf_up) %>% 
    filter(term == "victim_racenon-white") %>% 
    select(-term) 
  
  return(table)
  }
```

```{r fit logistic model}
# apply to all cities
all_logistic = homicides_data %>% 
  select(city_state, resolved, victim_race, victim_age, victim_sex) %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(glm = map(data, ~ glm(resolved ~ victim_age + victim_sex + victim_race, data = .x, family = binomial()))) %>% 
  mutate(output = map(glm, race_compare)) %>%
  select(city_state, output) %>% 
  unnest() %>% 
  select(-c(log_OR, p.value))

knitr::kable(all_logistic, digits = 3)
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r plot, fig.width=12}
all_logistic %>% 
  mutate(city_state, city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_up)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7), plot.title = element_text(hjust = 0.5, size = 12)) +
  labs(title = "Adjusted ORs and CIs for Solving Homicides Comparing Non-white Victims to White Victims",
       y = "Adjusted Odds Ratio",
       x = "City State")
```

__Comment__

Most of the cities have `Adjusted OR` below 1 except `Birmingham, AL`, `Durham, NC`, `Tampa, FL`. `Adjusted OR` less than 1 means the homicides of non-white victims are less likely to be solved than those of white victims. `Boston, MA` has the lowest `Adjusted OR` and `Tampa, FL` has the highest `Adjusted OR`.

### Problem 2

#### 2.1
Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

```{r p2 import data}
bw_raw = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names()
# look at the data
skimr::skim_to_wide(bw_raw) %>%  
  knitr::kable()
```

The dataset includes __3__ numeric variables and __17__ integer variables. There are no missing data in the raw dataset. By looking at the skim table, I think there are several variables need to be converted to factors, which are `babysex`, `frace`, `malforom`, and `mrace`.

```{r tidy data}
bw_data = bw_raw %>% 
  mutate(babysex, babysex = as.factor(babysex),
         frace, frace = as.factor(frace),
         malform, malform = as.factor(malform),
         mrace, mrace = as.factor(mrace))
```

```{r model select function}
best <- function(model, ...) 
{
  subsets <- regsubsets(formula(model), model.frame(model), ...)
  subsets <- with(summary(subsets),
                  cbind(p = as.numeric(rownames(which)), which, rss, rsq, adjr2, cp, bic))
  
  return(subsets)
}  
```

```{r bulid my model}
# fit a model with all predictors
bwt_fit = lm(bwt ~ ., data = bw_data)
# conduct a stepwise
step(bwt_fit, direction = 'backward')

best_tb = best(bwt_fit, nbest = 1) 
knitr::kable(best_tb)
```

__Description__

First, by doing a `backward` search procedure, the model starts with all predictors and removes the predictor with highest p-value. It turns out the best fit is `bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken`, which has the lowest `AIC = 48705.38` and therefore has the most parsimonious fit.

Then, I use a function based on `leaps::regsubsets` to take a look at the Criterian-Based Parameters of 


```{r}
bwt_best = lm(bwt ~ babysex + bhead + blength + delwt + frace + gaweeks + mrace + ppbmi + smoken, data = bw_data)
plot(bwt_best)

bw_data %>% 
  select(bwt, babysex, bhead, blength, delwt, fincome, gaweeks, mrace, ppbmi, smoken) %>% 
  add_residuals(bwt_best) %>% 
  add_predictions(bwt_best) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_smooth() +
  labs(title = "Residuals against fitted values")
```

Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

Note that although we expect your model to be reasonable, model building itself is not a main idea of the course and we don’t necessarily expect your model to be “optimal”.

```{r }

```

